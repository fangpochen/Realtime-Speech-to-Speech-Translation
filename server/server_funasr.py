""" Server for real-time translation and voice synthesization using FunASR """
from typing import Dict
from queue import Queue
import select
import socket
import pyaudio
import torch
import requests
import numpy as np
import urllib.parse
import os
from gradio_client import Client, file
from models.speech_recognition_funasr import FunASRSpeechRecognitionModel
from models.translator import Translator
from gpt_sovits_config import GPTSoVITSConfig

class AudioSocketServerFunASR:
    """ Class that handles real-time translation and voice synthesization using FunASR
        Socket input -> FunASR -> text -> TextToSpeech -> Socket output
    """
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 44100
    CHUNK = 4096
    PORT = 4444
    # Number of unaccepted connections before server refuses new connections.
    BACKLOG = 5
    
    def __init__(self, funasr_model="paraformer-zh", gpt_sovits_api="http://localhost:9872"):
        self.audio = pyaudio.PyAudio()
        self.serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        # Let kernel know we want to reuse the same port for restarting the server
        self.serversocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        # TODO: For multiple concurrent users we will need more queues
        self.data_queue : Queue = Queue()

        # Initialize the FunASR transcriber model
        self.transcriber = FunASRSpeechRecognitionModel(
            model_name=funasr_model,
            data_queue=self.data_queue,
            generation_callback=self.handle_generation,
            final_callback=self.handle_transcription
        )
        
        # åˆå§‹åŒ–GPT-SoVITSé…ç½®
        self.gpt_config = GPTSoVITSConfig()
        self.gpt_config.api_url = gpt_sovits_api.rstrip('/')
        print(f"ðŸš€ è¿žæŽ¥åˆ°GPT-SoVITS API: {self.gpt_config.api_url}")
        
        # åˆå§‹åŒ–Gradioå®¢æˆ·ç«¯
        try:
            self.gpt_sovits_client = Client(self.gpt_config.api_url, ssl_verify=False)
            print("âœ… Gradio Client åˆå§‹åŒ–æˆåŠŸ (SSLéªŒè¯å·²ç¦ç”¨)")
        except Exception as e:
            print(f"âŒ Gradio Client åˆå§‹åŒ–å¤±è´¥: {e}")
            print("   è¯·æ£€æŸ¥GradioæœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œï¼Œä»¥åŠSSL_CERT_FILEçŽ¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®ï¼ˆå¦‚æžœæœªä½¿ç”¨ssl_verify=Falseï¼‰ã€‚")
            # å¯ä»¥é€‰æ‹©åœ¨è¿™é‡ŒæŠ›å‡ºå¼‚å¸¸æˆ–å…è®¸æœåŠ¡å™¨ç»§ç»­è¿è¡Œä½†TTSåŠŸèƒ½å—é™
            self.gpt_sovits_client = None # æ ‡è®°å®¢æˆ·ç«¯ä¸å¯ç”¨
        
        # å‚è€ƒéŸ³é¢‘é…ç½®
        self.ref_wav_path = os.path.abspath(self.gpt_config.ref_wav_path)
        self.ref_text_path = os.path.abspath(self.gpt_config.ref_text_path)
        
        # è¯»å–å‚è€ƒæ–‡æœ¬
        try:
            with open(self.ref_text_path, 'r', encoding='utf-8') as f:
                self.ref_text = f.read().strip()
            print(f"ðŸ“ å‚è€ƒæ–‡æœ¬: {self.ref_text}")
        except Exception as e:
            print(f"âŒ è¯»å–å‚è€ƒæ–‡æœ¬å¤±è´¥: {e}")
            self.ref_text = "å¯ä»¥å¯ä»¥å¯ä»¥ã€‚é‚£æˆ‘å…ˆä¸ŠåŽ»ã€‚ä½ ç­‰ä¸‹å°±åˆ°é‚£ä¸ªåŠžå…¬å®¤é‡ŒåŽ»å“ˆ"
        
        # åˆå§‹åŒ–ç¿»è¯‘å™¨
        self.translator = Translator(service="google")  # ä½¿ç”¨Googleç¿»è¯‘
        
        self.read_list = []

    def __del__(self):
        self.audio.terminate()
        self.transcriber.stop()
        self.serversocket.shutdown()
        self.serversocket.close()
        
    def handle_generation(self, packet: Dict):
        """ Placeholder function for transcription"""
        pass
        
    def handle_transcription(self, packet: str, client_socket):
        """ Callback function to put finalized transcriptions into TTS"""
        print(f"ðŸŽ¤ è¯†åˆ«ç»“æžœ: '{packet}'")
        
        if not packet or not packet.strip():
            print("âš ï¸  è¯†åˆ«ç»“æžœä¸ºç©ºï¼Œè·³è¿‡ç¿»è¯‘")
            return
        
        # ç¿»è¯‘ä¸ºè‹±æ–‡
        print(f"ðŸ”„ å¼€å§‹ç¿»è¯‘...")
        translated_text = self.translator.translate_to_english(packet)
        print(f"ðŸŒ ç¿»è¯‘ç»“æžœ: '{translated_text}'")
        
        if translated_text and translated_text.strip():
            print(f"ðŸ”Š å¼€å§‹GPT-SoVITSè¯­éŸ³åˆæˆ...")
            # ä½¿ç”¨GPT-SoVITSåˆæˆè‹±æ–‡è¯­éŸ³
            audio_data = self.gpt_sovits_synthesize(translated_text, "en")
            if audio_data:
                self.stream_audio_to_client(audio_data, client_socket)
        else:
            print("âš ï¸  ç¿»è¯‘ç»“æžœä¸ºç©ºï¼Œè·³è¿‡è¯­éŸ³åˆæˆ")

    def gpt_sovits_synthesize(self, text: str, text_language: str = "en"):
        """è°ƒç”¨GPT-SoVITS /inference APIè¿›è¡Œè¯­éŸ³åˆæˆ"""
        if not self.gpt_sovits_client:
            print("âŒ GPT-SoVITSå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•è¿›è¡Œè¯­éŸ³åˆæˆã€‚")
            return None
        try:
            print(f"ðŸ”Š å¼€å§‹GPT-SoVITSåˆæˆ (API: /inference): '{text}'")
            
            # æ ¹æ®ç›®æ ‡è¯­è¨€è®¾ç½®å‚è€ƒéŸ³é¢‘è¯­è¨€
            prompt_language_literal = self.gpt_config.get_language("zh")  # å‚è€ƒéŸ³é¢‘æ˜¯ä¸­æ–‡
            text_language_literal = self.gpt_config.get_language(text_language) # ç›®æ ‡åˆæˆè¯­è¨€
            
            # ä»Ž self.gpt_config èŽ·å–å‚æ•°ï¼Œå¦‚æžœå±žæ€§ä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
            # è¿™äº›é»˜è®¤å€¼åº”ä¸Ž /inference API çš„é»˜è®¤å€¼æˆ–æ‚¨çš„æœŸæœ›ç›¸åŒ¹é…
            ref_audio_path_to_use = self.ref_wav_path # æ—§çš„å±žæ€§åï¼Œä½†è·¯å¾„åº”æŒ‡å‘ä¸»å‚è€ƒ
            prompt_text_to_use = self.ref_text

            top_k_to_use = getattr(self.gpt_config, 'top_k', 5) 
            top_p_to_use = getattr(self.gpt_config, 'top_p', 1.0)
            temperature_to_use = getattr(self.gpt_config, 'temperature', 1.0)
            
            # æ˜ å°„æ—§å‚æ•°ååˆ°æ–°å‚æ•°åï¼Œå¹¶ä»ŽconfigèŽ·å–æˆ–ä½¿ç”¨é»˜è®¤å€¼
            text_split_method_to_use = getattr(self.gpt_config, 'text_split_method', getattr(self.gpt_config, 'how_to_cut', "å‡‘å››å¥ä¸€åˆ‡"))
            speed_factor_to_use = getattr(self.gpt_config, 'speed_factor', getattr(self.gpt_config, 'speed', 1.0))
            ref_text_free_to_use = getattr(self.gpt_config, 'ref_text_free', getattr(self.gpt_config, 'ref_free', False))
            fragment_interval_to_use = getattr(self.gpt_config, 'fragment_interval', getattr(self.gpt_config, 'pause_second', 0.3))
            
            # æ–° /inference API ç‰¹å®šå‚æ•°
            seed_to_use = float(getattr(self.gpt_config, 'seed', -1.0)) # ç¡®ä¿æ˜¯float
            keep_random_to_use = getattr(self.gpt_config, 'keep_random', True)
            sample_steps_to_use = str(getattr(self.gpt_config, 'sample_steps', "32")) # ç¡®ä¿æ˜¯str

            # å…¶ä»– /inference API å‚æ•° (å½“å‰ä»Ž config èŽ·å–æˆ–ä½¿ç”¨ç¡¬ç¼–ç çš„ API é»˜è®¤å€¼)
            # ç”¨æˆ·å¯èƒ½å¸Œæœ›å°†è¿™äº›ä¹ŸåŠ å…¥ GPTSoVITSConfig
            batch_size_to_use = getattr(self.gpt_config, 'batch_size', 20.0)
            split_bucket_to_use = getattr(self.gpt_config, 'split_bucket', True)
            parallel_infer_to_use = getattr(self.gpt_config, 'parallel_infer', True)
            repetition_penalty_to_use = getattr(self.gpt_config, 'repetition_penalty', 1.35)
            super_sampling_to_use = getattr(self.gpt_config, 'super_sampling', getattr(self.gpt_config, 'if_sr', False))


            print(f"   [GPT-SoVITS Params] Seed: {seed_to_use}, KeepRandom: {keep_random_to_use}, Temp: {temperature_to_use}")
            print(f"   [GPT-SoVITS Params] TopK: {top_k_to_use}, TopP: {top_p_to_use}, SampleSteps: {sample_steps_to_use}")

            # è°ƒç”¨GPT-SoVITS /inference API
            result_tuple = self.gpt_sovits_client.predict(
                text=text,
                text_lang=text_language_literal, # ä½¿ç”¨è½¬æ¢åŽçš„å­—é¢é‡
                ref_audio_path=file(ref_audio_path_to_use), # å‚æ•°åæ›´æ”¹
                aux_ref_audio_paths=[], # å¿…éœ€å‚æ•°ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨
                prompt_text=prompt_text_to_use,
                prompt_lang=prompt_language_literal, # ä½¿ç”¨è½¬æ¢åŽçš„å­—é¢é‡
                top_k=top_k_to_use,
                top_p=top_p_to_use,
                temperature=temperature_to_use,
                text_split_method=text_split_method_to_use, # å‚æ•°åæ›´æ”¹
                speed_factor=speed_factor_to_use, # å‚æ•°åæ›´æ”¹
                ref_text_free=ref_text_free_to_use, # æ–°å‚æ•° (æˆ–æ—§å‚æ•°æ˜ å°„)
                split_bucket=split_bucket_to_use, # æ–°å‚æ•°
                fragment_interval=fragment_interval_to_use, # æ–°å‚æ•° (æˆ–æ—§å‚æ•°æ˜ å°„)
                seed=seed_to_use, # æ–°å‚æ•°
                keep_random=keep_random_to_use, # æ–°å‚æ•°
                parallel_infer=parallel_infer_to_use, # æ–°å‚æ•°
                repetition_penalty=repetition_penalty_to_use, # æ–°å‚æ•°
                sample_steps=sample_steps_to_use, # å‚æ•°ç±»åž‹å¯èƒ½å˜åŒ–ï¼Œç¡®ä¿æ˜¯str
                super_sampling=super_sampling_to_use, # æ–°å‚æ•° (æˆ–æ—§å‚æ•°æ˜ å°„)
                batch_size=batch_size_to_use, # æ–°å‚æ•°
                api_name="/inference" # æ˜Žç¡®æŒ‡å®šæ–°çš„APIç«¯ç‚¹
            )
            
            # å¤„ç† /inference API çš„è¿”å›žç»“æžœ (filepath, seed_float)
            if isinstance(result_tuple, tuple) and len(result_tuple) == 2:
                output_audio_path, returned_seed = result_tuple
                print(f"   [GPT-SoVITS API] Returned audio path: {output_audio_path}, Returned seed: {returned_seed}")
                if output_audio_path and os.path.exists(output_audio_path):
                    with open(output_audio_path, 'rb') as f:
                        audio_data = f.read()
                    print(f"ðŸ”Š GPT-SoVITSåˆæˆå®Œæˆ: '{text}' éŸ³é¢‘å¤§å°: {len(audio_data)} bytes, ä½¿ç”¨Seed: {returned_seed}")
                    # os.remove(output_audio_path) # å¯é€‰ï¼šåˆ é™¤æœåŠ¡ç«¯çš„ä¸´æ—¶æ–‡ä»¶
                    return audio_data
                else:
                    print(f"âŒ GPT-SoVITS /inference APIè¿”å›žæ— æ•ˆéŸ³é¢‘è·¯å¾„: {output_audio_path}")
                    return None
            else:
                print(f"âŒ GPT-SoVITS /inference APIè¿”å›žç»“æžœæ ¼å¼ä¸ç¬¦åˆé¢„æœŸ (åº”ä¸ºå…ƒç»„): {result_tuple}")
                return None
                
        except Exception as e:
            print(f"âŒ GPT-SoVITSåˆæˆå¤±è´¥ (è°ƒç”¨/inference): {e}")
            import traceback
            traceback.print_exc() # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯å †æ ˆ
            return None

    def stream_audio_to_client(self, audio_data: bytes, client_socket):
        """å°†éŸ³é¢‘æ•°æ®å‘é€åˆ°å®¢æˆ·ç«¯"""
        try:
            if client_socket and hasattr(client_socket, 'sendall'):
                # è·³è¿‡WAVæ–‡ä»¶å¤´ï¼Œç›´æŽ¥å‘é€éŸ³é¢‘æ•°æ®
                if len(audio_data) > 44:
                    audio_bytes = audio_data[44:]  # è·³è¿‡WAVå¤´
                else:
                    audio_bytes = audio_data
                
                client_socket.sendall(audio_bytes)
                print(f"âœ… GPT-SoVITSéŸ³é¢‘å·²å‘é€åˆ°å®¢æˆ·ç«¯ï¼Œå¤§å°: {len(audio_bytes)} bytes")
            else:
                print("âš ï¸  å®¢æˆ·ç«¯è¿žæŽ¥å·²æ–­å¼€ï¼Œæ— æ³•å‘é€éŸ³é¢‘")
        except (ConnectionResetError, BrokenPipeError, OSError) as e:
            print(f"âŒ å‘é€éŸ³é¢‘å¤±è´¥: {e}")
            if client_socket in self.read_list:
                self.read_list.remove(client_socket)

    def start(self):
        """ Starts the server"""
        self.transcriber.start(16000, 2)
        print(f"ðŸš€ GPT-SoVITS Translation Server listening on port {self.PORT}")
        print(f"ðŸ“¡ Connected to GPT-SoVITS API: {self.gpt_config.api_url}")
        self.serversocket.bind(('', self.PORT))
        self.serversocket.listen(self.BACKLOG)
        # Contains all of the socket connections
        self.read_list = [self.serversocket]

        try:
            while True:
                readable, _, _ = select.select(self.read_list, [], [])
                for s in readable:
                    if s is self.serversocket:
                        (clientsocket, address) = self.serversocket.accept()
                        self.read_list.append(clientsocket)
                        print("Connection from", address)
                    else:
                        try:
                            data = s.recv(4096)
                            if data:
                                print(f"ðŸ“¥ æ”¶åˆ°éŸ³é¢‘æ•°æ®: {len(data)} bytes")
                                self.data_queue.put((s, data))
                            else:
                                self.read_list.remove(s)
                                print("Disconnection from", address)
                        except ConnectionResetError:
                            self.read_list.remove(s)
                            print("Client crashed from", address)
        except KeyboardInterrupt:
            pass
        print("Performing server cleanup")
        self.audio.terminate()
        self.transcriber.stop()
        self.serversocket.shutdown(socket.SHUT_RDWR)
        self.serversocket.close()
        print("Sockets cleaned up")

    def update_gpt_sovits_config(self, **kwargs):
        """æ›´æ–°GPT-SoVITSé…ç½®å‚æ•°"""
        self.gpt_config.update_config(**kwargs)
        
    def get_gpt_sovits_config(self):
        """èŽ·å–å½“å‰GPT-SoVITSé…ç½® (é€‚é… /inference API)"""
        config_dict = {
            'api_url': self.gpt_config.api_url,
            'ref_wav_path': self.gpt_config.ref_wav_path,
            'ref_text_path': self.gpt_config.ref_text_path,
            
            # /inference API å‚æ•°
            'top_k': self.gpt_config.top_k,
            'top_p': self.gpt_config.top_p,
            'temperature': self.gpt_config.temperature,
            'sample_steps': self.gpt_config.sample_steps, # str
            
            'text_split_method': self.gpt_config.text_split_method,
            'fragment_interval': self.gpt_config.fragment_interval,
            
            'speed_factor': self.gpt_config.speed_factor,
            'seed': self.gpt_config.seed, # float
            'keep_random': self.gpt_config.keep_random, # bool
            
            'ref_text_free': self.gpt_config.ref_text_free,
            'super_sampling': self.gpt_config.super_sampling,
            
            # é«˜çº§/æ€§èƒ½å‚æ•°
            'batch_size': self.gpt_config.batch_size,
            'split_bucket': self.gpt_config.split_bucket,
            'parallel_infer': self.gpt_config.parallel_infer,
            'repetition_penalty': self.gpt_config.repetition_penalty,
        }
        return config_dict

if __name__ == "__main__":
    import sys
    
    gpt_sovits_api = "http://localhost:9872"
    if len(sys.argv) > 1:
        gpt_sovits_api = sys.argv[1]
    
    server = AudioSocketServerFunASR(
        funasr_model="paraformer-zh",
        gpt_sovits_api=gpt_sovits_api
    )
    server.start() 