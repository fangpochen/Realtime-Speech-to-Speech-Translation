#!/usr/bin/env python3
"""æµ‹è¯•gradio_clientè¿æ¥GPT-SoVITS Inference API"""

import os
import sys
import traceback
import random
from gradio_client import Client, file

def test_gradio_client(api_url="http://localhost:9872",
                       text_to_synthesize="hello. im from American",
                       text_lang_param="è‹±æ–‡",
                       # ä»¥ä¸‹å‚æ•°å°†ä»å›ºå®šè·¯å¾„åŠ è½½ï¼Œä¸å†ä½œä¸ºå‡½æ•°å‚æ•°
                       # ref_audio_path_param=os.path.abspath("server/tts_wav/1.wav"), 
                       # prompt_text_param="", 
                       # prompt_lang_param="ä¸­æ–‡", 
                       top_k_param=5,
                       top_p_param=1.0,
                       temperature_param=1.0,
                       text_split_method_param="å‡‘å››å¥ä¸€åˆ‡",
                       speed_factor_param=1.0,
                       seed_param=-1.0, 
                       keep_random_param=True, 
                       sample_steps_param="32",
                       ):
    """æµ‹è¯•gradio_clientè¿æ¥ /inference API"""

    # å›ºå®šå‚è€ƒéŸ³é¢‘å’Œæ–‡æœ¬é€»è¾‘
    fixed_ref_audio_path = os.path.abspath("server/tts_wav/1.wav")
    fixed_ref_text_path = os.path.abspath("server/tts_wav/1.txt")
    fixed_prompt_lang = "ä¸­æ–‡"

    print(f"ğŸ§ª æµ‹è¯•Gradio Clientè¿æ¥: {api_url} (API: /inference)")
    print(f"ğŸ“œ åˆæˆæ–‡æœ¬: '{text_to_synthesize}' ({text_lang_param})")
    # æ›´æ–°æ‰“å°ä»¥åæ˜ å›ºå®šå€¼
    print(f"ğŸ¤ ä¸»å‚è€ƒéŸ³é¢‘ (å›ºå®š): {fixed_ref_audio_path}")
    # (å‚è€ƒæ–‡æœ¬å†…å®¹ä¼šåœ¨è¯»å–åæ‰“å°)
    print(f"ğŸ—£ï¸ å‚è€ƒè¯­ç§ (å›ºå®š): {fixed_prompt_lang}")
    print(f"ğŸ” Top_k: {top_k_param}")
    print(f"ğŸ¯ Top_p: {top_p_param}")
    print(f"ğŸŒ¡ï¸ Temperature: {temperature_param}")
    print(f"ğŸ”ª åˆ‡å‰²æ–¹æ³•: {text_split_method_param}")
    print(f"â© è¯­é€Ÿå› å­: {speed_factor_param}")
    print(f"ğŸŒ± Seed: {seed_param}")
    print(f"â“ Keep Random: {keep_random_param}")
    print(f"ğŸ‘£ Sample Steps: {sample_steps_param}")

    # å®¢æˆ·ç«¯ç§å­è®¾ç½® (ä¸»è¦å½±å“å®¢æˆ·ç«¯çš„éšæœºæ€§ï¼Œå¯¹æœåŠ¡ç«¯æ•ˆæœæœ‰é™ï¼Œä½†ä¿æŒä»¥é˜²ä¸‡ä¸€)
    # æœåŠ¡ç«¯ç§å­ç”± seed_param æ§åˆ¶ä¼ é€’ç»™API
    if seed_param != -1.0:
        try:
            actual_client_seed = int(seed_param)
            print(f"ğŸŒ± (å®¢æˆ·ç«¯ä¾§)è®¾ç½®éšæœºç§å­: {actual_client_seed}")
            random.seed(actual_client_seed)
        except ValueError:
            print(f"âš ï¸ æ— æ³•å°†seed '{seed_param}' è½¬ä¸ºæ•´æ•°ç”¨äºå®¢æˆ·ç«¯random.seed().")
    else:
        print(f"ğŸŒ± (å®¢æˆ·ç«¯ä¾§)éšæœºç§å­: æœªç‰¹åˆ«è®¾ç½® (ä½¿ç”¨ç³»ç»Ÿéšæœºæ€§)")

    try:
        print(f"\nğŸ”— æ­£åœ¨è¿æ¥åˆ°GradioæœåŠ¡... (SSLéªŒè¯ç¦ç”¨)")
        client = Client(api_url, ssl_verify=False)
        print(f"âœ… Gradio Clientè¿æ¥æˆåŠŸ (SSLéªŒè¯å·²ç¦ç”¨)")

        # æ£€æŸ¥å›ºå®šå‚è€ƒæ–‡ä»¶è·¯å¾„
        if not os.path.exists(fixed_ref_audio_path):
            print(f"âŒ ä¸»å‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {fixed_ref_audio_path}")
            return False
        print(f"âœ… ä¸»å‚è€ƒéŸ³é¢‘æ–‡ä»¶æ£€æŸ¥é€šè¿‡: {fixed_ref_audio_path}")

        if not os.path.exists(fixed_ref_text_path):
            print(f"âŒ å‚è€ƒæ–‡æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {fixed_ref_text_path}")
            return False
        print(f"âœ… å‚è€ƒæ–‡æœ¬æ–‡ä»¶æ£€æŸ¥é€šè¿‡: {fixed_ref_text_path}")
        
        with open(fixed_ref_text_path, 'r', encoding='utf-8') as f:
            fixed_prompt_text = f.read().strip()
        print(f"ğŸ“ å‚è€ƒæ–‡æœ¬ (å›ºå®šå†…å®¹): '{fixed_prompt_text}'")

        # æ„å»ºä¼ é€’ç»™predictçš„å‚æ•°å­—å…¸
        # è¯¥å­—å…¸å°†åŒ…å«æ‰€æœ‰APIå®šä¹‰çš„å‚æ•°ï¼Œæ˜ç¡®æŒ‡å®šå€¼æˆ–ä½¿ç”¨APIæ–‡æ¡£ä¸­çš„é»˜è®¤å€¼
        predict_params = {
            # ä»å‡½æ•°å‚æ•°æˆ–å›ºå®šå€¼è·å–
            "text": text_to_synthesize,
            "text_lang": text_lang_param,
            "ref_audio_path": file(fixed_ref_audio_path),
            "aux_ref_audio_paths": [], # å¿…éœ€ï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨
            "prompt_text": fixed_prompt_text,
            "prompt_lang": fixed_prompt_lang,
            "top_k": top_k_param, # APIé»˜è®¤5, å¯ç”±å‘½ä»¤è¡Œè¦†ç›–
            "top_p": top_p_param, # APIé»˜è®¤1.0, å¯ç”±å‘½ä»¤è¡Œè¦†ç›–
            "temperature": temperature_param, # APIé»˜è®¤1.0, å¯ç”±å‘½ä»¤è¡Œè¦†ç›–
            "text_split_method": text_split_method_param, # APIé»˜è®¤"å‡‘å››å¥ä¸€åˆ‡", å¯ç”±å‘½ä»¤è¡Œè¦†ç›–
            "speed_factor": speed_factor_param, # APIé»˜è®¤1.0, å¯ç”±å‘½ä»¤è¡Œè¦†ç›–
            "seed": float(seed_param), # APIé»˜è®¤-1.0, å¯ç”±å‘½ä»¤è¡Œè¦†ç›–
            "keep_random": keep_random_param, # APIé»˜è®¤True, å¯ç”±å‘½ä»¤è¡Œè¦†ç›–
            "sample_steps": sample_steps_param, # APIé»˜è®¤"32", å¯ç”±å‘½ä»¤è¡Œè¦†ç›–

            # æ ¹æ®APIæ–‡æ¡£æ·»åŠ å…¶ä»–å‚æ•°åŠå…¶é»˜è®¤å€¼ (è¿™äº›å½“å‰ä¸ç”±å‘½ä»¤è¡Œæ§åˆ¶)
            "batch_size": 20.0,  # API Default: 20 (float)
            "ref_text_free": False, # API Default: False
            "split_bucket": True,  # API Default: True
            "fragment_interval": 0.3, # API Default: 0.3
            "parallel_infer": True, # API Default: True
            "repetition_penalty": 1.35, # API Default: 1.35
            "super_sampling": False, # API Default: False
            
            "api_name": "/inference" # æŒ‡å®šAPIç«¯ç‚¹
        }
        
        print("\n[DEBUG] å®é™…è°ƒç”¨ predict çš„æ‰€æœ‰å‚æ•° (åŒ…æ‹¬APIé»˜è®¤å€¼):")
        for key, value in predict_params.items():
            if key == "ref_audio_path": 
                 print(f"   {key}: {fixed_ref_audio_path} (gradio.file object)") # æ‰“å°å›ºå®šè·¯å¾„
            else:
                 print(f"   {key}: {value}")
        print("\n")

        print(f"ğŸ”Š å¼€å§‹TTSåˆæˆæµ‹è¯• (API: /inference)... ")
        result_tuple = client.predict(**predict_params)
        
        print(f"âœ… TTSåˆæˆæˆåŠŸ!")
        if isinstance(result_tuple, tuple) and len(result_tuple) == 2:
            output_audio_path, returned_seed = result_tuple
            print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_audio_path}")
            print(f"ğŸŒ± æœåŠ¡ç«¯è¿”å›çš„Seed: {returned_seed}")
            
            if output_audio_path and os.path.exists(output_audio_path):
                file_size = os.path.getsize(output_audio_path)
                print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size} bytes")
                
                import shutil
                output_filename = "test_gradio_inference_output.wav"
                shutil.copy2(output_audio_path, output_filename)
                print(f"âœ… éŸ³é¢‘å·²å¤åˆ¶åˆ°: {os.path.abspath(output_filename)}")
                return True
            else:
                print(f"âŒ è¾“å‡ºæ–‡ä»¶æ— æ•ˆæˆ–ä¸å­˜åœ¨: {output_audio_path}")
                return False
        else:
            print(f"âŒ APIè¿”å›ç»“æœæ ¼å¼ä¸ç¬¦åˆé¢„æœŸ: {result_tuple}")
            return False
            
    except Exception as e:
        print(f"âŒ Gradio Clientæµ‹è¯•å¤±è´¥: {e}")
        print(f"ğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        return False

def test_simple_connection(api_url="http://localhost:9872"):
    """æµ‹è¯•ç®€å•è¿æ¥"""
    try:
        print(f"ğŸ”— æµ‹è¯•ç®€å•è¿æ¥... (SSLéªŒè¯ç¦ç”¨)")
        client = Client(api_url, ssl_verify=False)
        print(f"âœ… Gradio Clientè¿æ¥æˆåŠŸ (SSLéªŒè¯å·²ç¦ç”¨)")
        
        # å°è¯•è·å–APIä¿¡æ¯
        print(f"ğŸ“‹ APIä¿¡æ¯:")
        # print(f"   - ç«¯ç‚¹: {client.endpoints}") # May cause issues if API is not fully responsive
        
        return True
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")
        traceback.print_exc()
        return False

if __name__ == "__main__":
    # é»˜è®¤å‚æ•°è®¾ç½®åŒºåŸŸ
    api_url_cli = "http://localhost:9872"
    text_cli = "hello. im from American"
    text_lang_cli = "è‹±æ–‡"
    # ä»¥ä¸‹ä¸‰ä¸ªå‚æ•°ä¸å†ä»å‘½ä»¤è¡Œè¯»å–ï¼Œå°†ä½¿ç”¨å‡½æ•°å†…éƒ¨çš„å›ºå®šå€¼
    # ref_audio_cli = os.path.abspath("server/tts_wav/1.wav") 
    # prompt_text_cli = "" 
    # prompt_lang_cli = "ä¸­æ–‡"
    top_k_cli = 5
    top_p_cli = 1.0
    temperature_cli = 1.0
    text_split_method_cli = "å‡‘å››å¥ä¸€åˆ‡"
    speed_factor_cli = 1.0
    seed_cli = -1.0 
    keep_random_cli = True 
    sample_steps_cli = "32" 

    # å‘½ä»¤è¡Œå‚æ•°è§£æ (ç®€å•ç‰ˆæœ¬ï¼Œåç»­å¯å¢å¼º)
    args = sys.argv[1:] # è·³è¿‡è„šæœ¬å
    # è°ƒæ•´å‚æ•°ç´¢å¼•å› ä¸ºç§»é™¤äº†3ä¸ªå‚æ•°
    if len(args) > 0: api_url_cli = args[0]
    if len(args) > 1: text_cli = args[1]
    if len(args) > 2: text_lang_cli = args[2]
    # args[3], args[4], args[5] åŸç”¨äº ref_audio, prompt_text, prompt_langï¼Œç°å·²ç§»é™¤
    if len(args) > 3: top_k_cli = int(args[3]) # åŸ args[6]
    if len(args) > 4: top_p_cli = float(args[4]) # åŸ args[7]
    if len(args) > 5: temperature_cli = float(args[5]) # åŸ args[8]
    if len(args) > 6: text_split_method_cli = args[6] # åŸ args[9]
    if len(args) > 7: speed_factor_cli = float(args[7]) # åŸ args[10]
    if len(args) > 8: seed_cli = float(args[8]) # åŸ args[11]
    if len(args) > 9: # åŸ args[12]
        val = args[9].lower()
        if val == "true" or val == "1": keep_random_cli = True
        elif val == "false" or val == "0": keep_random_cli = False
        else: print(f"âš ï¸ æ— æ•ˆçš„keep_randomå‚æ•°å€¼ '{args[9]}'. ä½¿ç”¨é»˜è®¤å€¼ {keep_random_cli}.")
    if len(args) > 10: sample_steps_cli = args[10] # åŸ args[13]

    print("=" * 60)
    print(f"Gradio Client TTS (/inference) æµ‹è¯•")
    print(f"  API URL: {api_url_cli}")
    print(f"  åˆæˆæ–‡æœ¬: \"{text_cli}\" ({text_lang_cli})")
    # æ›´æ–°æ‰“å°ä»¥åæ˜ å›ºå®šå‚è€ƒ
    print(f"  ä¸»å‚è€ƒéŸ³é¢‘: (å›ºå®šè·¯å¾„ server/tts_wav/1.wav)")
    print(f"  å‚è€ƒæ–‡æœ¬: (å›ºå®šä» server/tts_wav/1.txt è¯»å–)")
    print(f"  å‚è€ƒè¯­ç§: (å›ºå®šä¸º ä¸­æ–‡)")
    print(f"  Top_k: {top_k_cli}, Top_p: {top_p_cli}, Temperature: {temperature_cli}")
    print(f"  åˆ‡å‰²: {text_split_method_cli}, è¯­é€Ÿ: {speed_factor_cli}")
    print(f"  Seed: {seed_cli}, Keep Random: {keep_random_cli}, Sample Steps: {sample_steps_cli}")
    print("=" * 60)

    # åŸºæœ¬è¿æ¥æµ‹è¯•ä»ç„¶æœ‰ç”¨
    # if test_simple_connection(api_url_cli): # å¯ä»¥é€‰æ‹©æ€§è¿è¡Œ
    #     print("\nâœ… åŸºæœ¬è¿æ¥æµ‹è¯•é€šè¿‡.\n")
    
    success = test_gradio_client(
        api_url=api_url_cli,
        text_to_synthesize=text_cli,
        text_lang_param=text_lang_cli,
        # ä¸å†ä¼ é€’ ref_audio_path_param, prompt_text_param, prompt_lang_param
        top_k_param=top_k_cli,
        top_p_param=top_p_cli,
        temperature_param=temperature_cli,
        text_split_method_param=text_split_method_cli,
        speed_factor_param=speed_factor_cli,
        seed_param=seed_cli,
        keep_random_param=keep_random_cli,
        sample_steps_param=sample_steps_cli
    )

    if success:
        print(f"\nğŸ‰ Gradio Client TTS (/inference) æµ‹è¯•æˆåŠŸ!")
    else:
        print(f"\nâŒ Gradio Client TTS (/inference) æµ‹è¯•å¤±è´¥!")
    
    print("=" * 60) 