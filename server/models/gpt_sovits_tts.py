""" GPT-SoVITS Text to Speech with API Integration """
import requests
import json
import time
import io
import torch
import numpy as np
from typing import Optional
import urllib.parse

class GPTSoVITSTTSModel:
    """GPT-SoVITS TTSæ¨¡å‹ç±»ï¼Œé€šè¿‡APIè°ƒç”¨è¿›è¡Œè¯­éŸ³åˆæˆ"""
    
    def __init__(self, api_url="http://localhost:9872", callback_function=None):
        self.api_url = api_url.rstrip('/')
        self.callback_function = callback_function
        self.device = "cuda:0" if torch.cuda.is_available() else "cpu"
        
        # é»˜è®¤å‚è€ƒéŸ³é¢‘è®¾ç½®
        self.default_refer_wav_path = None
        self.default_prompt_text = None
        self.default_prompt_language = "zh"
        
        # æµ‹è¯•APIè¿æ¥
        self._test_connection()
        
        print(f"ğŸš€ GPT-SoVITS TTS API connected: {self.api_url}")
        
    def _test_connection(self):
        """æµ‹è¯•APIè¿æ¥"""
        try:
            response = requests.get(f"{self.api_url}/", timeout=5)
            if response.status_code != 200:
                raise ConnectionError(f"APIè¿”å›çŠ¶æ€ç : {response.status_code}")
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°GPT-SoVITS API: {e}")
            print(f"è¯·ç¡®ä¿GPT-SoVITSæœåŠ¡æ­£åœ¨è¿è¡Œåœ¨ {self.api_url}")
            raise e
    
    def synthesise(self, text: str, client_socket, 
                   refer_wav_path: Optional[str] = None,
                   prompt_text: Optional[str] = None,
                   prompt_language: str = "zh",
                   text_language: str = "zh"):
        """
        éé˜»å¡è¯­éŸ³åˆæˆ
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            client_socket: å®¢æˆ·ç«¯socket
            refer_wav_path: å‚è€ƒéŸ³é¢‘è·¯å¾„
            prompt_text: å‚è€ƒéŸ³é¢‘æ–‡æœ¬
            prompt_language: å‚è€ƒéŸ³é¢‘è¯­è¨€
            text_language: ç›®æ ‡æ–‡æœ¬è¯­è¨€
        """
        if self.callback_function:
            # å¼‚æ­¥å¤„ç†
            audio = self.synthesise_blocking(
                text, refer_wav_path, prompt_text, 
                prompt_language, text_language
            )
            self.callback_function(audio, client_socket)
    
    def synthesise_blocking(self, text: str,
                           refer_wav_path: Optional[str] = None,
                           prompt_text: Optional[str] = None,
                           prompt_language: str = "zh",
                           text_language: str = "zh") -> torch.Tensor:
        """
        é˜»å¡å¼è¯­éŸ³åˆæˆ
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            refer_wav_path: å‚è€ƒéŸ³é¢‘è·¯å¾„
            prompt_text: å‚è€ƒéŸ³é¢‘æ–‡æœ¬  
            prompt_language: å‚è€ƒéŸ³é¢‘è¯­è¨€
            text_language: ç›®æ ‡æ–‡æœ¬è¯­è¨€
            
        Returns:
            torch.Tensor: åˆæˆçš„éŸ³é¢‘æ•°æ®
        """
        start_time = time.time()
        
        try:
            # ä½¿ç”¨é»˜è®¤å‚è€ƒéŸ³é¢‘ï¼ˆå¦‚æœæ²¡æœ‰æä¾›çš„è¯ï¼‰
            if not refer_wav_path and self.default_refer_wav_path:
                refer_wav_path = self.default_refer_wav_path
                prompt_text = self.default_prompt_text
                prompt_language = self.default_prompt_language
            
            # æ ¹æ®æ˜¯å¦æœ‰å‚è€ƒéŸ³é¢‘é€‰æ‹©ä¸åŒçš„è°ƒç”¨æ–¹å¼
            if refer_wav_path and prompt_text:
                # ä½¿ç”¨POSTæ–¹å¼ï¼ŒåŒ…å«å‚è€ƒéŸ³é¢‘
                data = {
                    "refer_wav_path": refer_wav_path,
                    "prompt_text": prompt_text,
                    "prompt_language": prompt_language,
                    "text": text,
                    "text_language": text_language
                }
                
                response = requests.post(
                    f"{self.api_url}/",
                    json=data,
                    timeout=30
                )
            else:
                # ä½¿ç”¨GETæ–¹å¼ï¼Œä¸åŒ…å«å‚è€ƒéŸ³é¢‘
                params = {
                    "text": text,
                    "text_language": text_language
                }
                
                # æ„å»ºURLå‚æ•°
                query_string = urllib.parse.urlencode(params)
                url = f"{self.api_url}/?{query_string}"
                
                response = requests.get(url, timeout=30)
            
            if response.status_code == 200:
                # è·å–éŸ³é¢‘æ•°æ®
                audio_data = response.content
                
                if len(audio_data) == 0:
                    print("âš ï¸  æ”¶åˆ°ç©ºéŸ³é¢‘æ•°æ®")
                    return torch.zeros(16000)
                
                # å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºtorch tensor
                # GPT-SoVITSè¿”å›çš„æ˜¯WAVæ ¼å¼éŸ³é¢‘
                try:
                    # è·³è¿‡WAVæ–‡ä»¶å¤´ï¼ˆé€šå¸¸æ˜¯44å­—èŠ‚ï¼‰
                    if len(audio_data) > 44:
                        audio_bytes = audio_data[44:]  # è·³è¿‡WAVå¤´
                    else:
                        audio_bytes = audio_data
                    
                    # è½¬æ¢ä¸ºnumpyæ•°ç»„
                    audio_array = np.frombuffer(audio_bytes, dtype=np.int16)
                    
                    if len(audio_array) == 0:
                        print("âš ï¸  éŸ³é¢‘æ•°ç»„ä¸ºç©º")
                        return torch.zeros(16000)
                    
                    # è½¬æ¢ä¸ºfloat32å¹¶å½’ä¸€åŒ–
                    audio_tensor = torch.from_numpy(audio_array.astype(np.float32) / 32768.0)
                    
                    end_time = time.time()
                    print(f"ğŸ”Š GPT-SoVITSåˆæˆå®Œæˆ: '{text}' è€—æ—¶: {end_time - start_time:.2f}ç§’")
                    print(f"   éŸ³é¢‘é•¿åº¦: {len(audio_tensor)} æ ·æœ¬")
                    
                    return audio_tensor
                    
                except Exception as e:
                    print(f"âŒ éŸ³é¢‘æ•°æ®å¤„ç†å¤±è´¥: {e}")
                    # ç›´æ¥è¿”å›åŸå§‹æ•°æ®ä½œä¸ºtensor
                    audio_array = np.frombuffer(audio_data, dtype=np.uint8)
                    audio_tensor = torch.from_numpy(audio_array.astype(np.float32))
                    return audio_tensor
                
            else:
                print(f"âŒ GPT-SoVITS APIé”™è¯¯: {response.status_code}")
                print(f"é”™è¯¯å†…å®¹: {response.text}")
                # è¿”å›ç©ºéŸ³é¢‘
                return torch.zeros(16000)  # 1ç§’çš„é™éŸ³
                
        except Exception as e:
            print(f"âŒ GPT-SoVITSåˆæˆå¤±è´¥: {e}")
            # è¿”å›ç©ºéŸ³é¢‘
            return torch.zeros(16000)  # 1ç§’çš„é™éŸ³
    
    def set_reference_audio(self, wav_path: str, text: str, language: str = "zh"):
        """
        è®¾ç½®é»˜è®¤å‚è€ƒéŸ³é¢‘
        
        Args:
            wav_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            text: éŸ³é¢‘å¯¹åº”æ–‡æœ¬
            language: éŸ³é¢‘è¯­è¨€
        """
        self.default_refer_wav_path = wav_path
        self.default_prompt_text = text
        self.default_prompt_language = language
        print(f"âœ… è®¾ç½®é»˜è®¤å‚è€ƒéŸ³é¢‘: {wav_path}")
        print(f"   å‚è€ƒæ–‡æœ¬: {text}")
        print(f"   è¯­è¨€: {language}")
    
    def load_speaker_embeddings(self):
        """å…¼å®¹æ€§æ–¹æ³•ï¼ŒGPT-SoVITSä¸éœ€è¦é¢„åŠ è½½è¯´è¯äººåµŒå…¥"""
        print("âœ… GPT-SoVITSä¸éœ€è¦é¢„åŠ è½½è¯´è¯äººåµŒå…¥")
        pass 